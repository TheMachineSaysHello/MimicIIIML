{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosptial Mortality Classifcation\n",
    "this notebookes creates classifers that predict probablity that a patient died in the hospital based on lab values. It uses Phyisio Mimic III as a data source and uses the python evalML to evaluate classifers. m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_validate,  StratifiedKFold\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from evalml.automl import AutoMLSearch\n",
    "import evalml\n",
    "import os\n",
    "import re\n",
    "import mlflow\n",
    "from evalml.model_understanding.prediction_explanations import explain_predictions\n",
    "from mlflow.models.signature import infer_signature\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "#tracking_uri = \"http://localhost:5000\"\n",
    "#mlflow.set_tracking_uri(tracking_uri)\n",
    "#os.environ['MLFLOW_TRACKING_URI'] = tracking_uri\n",
    "#os.environ['MLFLOW_ARTIFACT_URI'] = tracking_uri\n",
    "MAX_MEMORY = \"12g\"\n",
    "data_dir = os.getenv('PHYSIO_HOME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading\n",
    "Data is loaded from Phyiso MimiIII amd saved as paquet to pyspark data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Egneineering \n",
    "creates a features data frame using max and min lab values during hospital stays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n_rows: 58144, n_features: 200, label_prob 0.1\n",
      "features: ['% Hemoglobin A1c_max' '% Hemoglobin A1c_min'\n",
      " 'Alanine Aminotransferase (ALT)_max' 'Alanine Aminotransferase (ALT)_min'\n",
      " 'Albumin_max' 'Albumin_min' 'Alkaline Phosphatase_max'\n",
      " 'Alkaline Phosphatase_min' 'Alveolar-arterial Gradient_max'\n",
      " 'Alveolar-arterial Gradient_min' 'Amylase_max' 'Amylase_min'\n",
      " 'Anion Gap_max' 'Anion Gap_min' 'Asparate Aminotransferase (AST)_max'\n",
      " 'Asparate Aminotransferase (AST)_min' 'Atypical Lymphocytes_max'\n",
      " 'Atypical Lymphocytes_min' 'Bands_max' 'Bands_min' 'Base Excess_max'\n",
      " 'Base Excess_min' 'Basophils_max' 'Basophils_min' 'Bicarbonate_max'\n",
      " 'Bicarbonate_min' 'Bilirubin, Direct_max' 'Bilirubin, Direct_min'\n",
      " 'Bilirubin, Indirect_max' 'Bilirubin, Indirect_min'\n",
      " 'Bilirubin, Total_max' 'Bilirubin, Total_min' 'CK-MB Index_max'\n",
      " 'CK-MB Index_min' 'Calcium, Total_max' 'Calcium, Total_min'\n",
      " 'Calculated Total CO2_max' 'Calculated Total CO2_min' 'Chloride_max'\n",
      " 'Chloride_min' 'Chloride, Whole Blood_max' 'Chloride, Whole Blood_min'\n",
      " 'Cholesterol Ratio (Total/HDL)_max' 'Cholesterol Ratio (Total/HDL)_min'\n",
      " 'Cholesterol, HDL_max' 'Cholesterol, HDL_min'\n",
      " 'Cholesterol, LDL, Calculated_max' 'Cholesterol, LDL, Calculated_min'\n",
      " 'Cholesterol, Total_max' 'Cholesterol, Total_min' 'Cortisol_max'\n",
      " 'Cortisol_min' 'Creatine Kinase (CK)_max' 'Creatine Kinase (CK)_min'\n",
      " 'Creatine Kinase, MB Isoenzyme_max' 'Creatine Kinase, MB Isoenzyme_min'\n",
      " 'Creatinine_max' 'Creatinine_min' 'Creatinine, Urine_max'\n",
      " 'Creatinine, Urine_min' 'Eosinophils_max' 'Eosinophils_min'\n",
      " 'Epithelial Cells_max' 'Epithelial Cells_min' 'Ferritin_max'\n",
      " 'Ferritin_min' 'Fibrinogen, Functional_max' 'Fibrinogen, Functional_min'\n",
      " 'Free Calcium_max' 'Free Calcium_min' 'Glucose_max' 'Glucose_min'\n",
      " 'Granulocyte Count_max' 'Granulocyte Count_min' 'Hematocrit_max'\n",
      " 'Hematocrit_min' 'Hematocrit, Calculated_max'\n",
      " 'Hematocrit, Calculated_min' 'Hemoglobin_max' 'Hemoglobin_min'\n",
      " 'INR(PT)_max' 'INR(PT)_min' 'Iron_max' 'Iron_min'\n",
      " 'Iron Binding Capacity, Total_max' 'Iron Binding Capacity, Total_min'\n",
      " 'Ketone_max' 'Ketone_min' 'Lactate_max' 'Lactate_min'\n",
      " 'Lactate Dehydrogenase (LD)_max' 'Lactate Dehydrogenase (LD)_min'\n",
      " 'Lipase_max' 'Lipase_min' 'Lymphocytes_max' 'Lymphocytes_min' 'MCH_max'\n",
      " 'MCH_min' 'MCHC_max' 'MCHC_min' 'MCV_max' 'MCV_min' 'Magnesium_max'\n",
      " 'Magnesium_min' 'Metamyelocytes_max' 'Metamyelocytes_min' 'Monocytes_max'\n",
      " 'Monocytes_min' 'Myelocytes_max' 'Myelocytes_min' 'Neutrophils_max'\n",
      " 'Neutrophils_min' 'Nucleated Red Cells_max' 'Nucleated Red Cells_min'\n",
      " 'O2 Flow_max' 'O2 Flow_min' 'Osmolality, Measured_max'\n",
      " 'Osmolality, Measured_min' 'Osmolality, Urine_max'\n",
      " 'Osmolality, Urine_min' 'Oxygen_max' 'Oxygen_min' 'Oxygen Saturation_max'\n",
      " 'Oxygen Saturation_min' 'PEEP_max' 'PEEP_min' 'PT_max' 'PT_min' 'PTT_max'\n",
      " 'PTT_min' 'Phenytoin_max' 'Phenytoin_min' 'Phosphate_max' 'Phosphate_min'\n",
      " 'Platelet Count_max' 'Platelet Count_min' 'Polys_max' 'Polys_min'\n",
      " 'Potassium_max' 'Potassium_min' 'Potassium, Urine_max'\n",
      " 'Potassium, Urine_min' 'Potassium, Whole Blood_max'\n",
      " 'Potassium, Whole Blood_min' 'Protein_max' 'Protein_min'\n",
      " 'Protein, Total_max' 'Protein, Total_min' 'RBC_max' 'RBC_min' 'RDW_max'\n",
      " 'RDW_min' 'Red Blood Cells_max' 'Red Blood Cells_min' 'Required O2_max'\n",
      " 'Required O2_min' 'Sodium_max' 'Sodium_min' 'Sodium, Urine_max'\n",
      " 'Sodium, Urine_min' 'Sodium, Whole Blood_max' 'Sodium, Whole Blood_min'\n",
      " 'Specific Gravity_max' 'Specific Gravity_min' 'Temperature_max'\n",
      " 'Temperature_min' 'Thyroid Stimulating Hormone_max'\n",
      " 'Thyroid Stimulating Hormone_min' 'Tidal Volume_max' 'Tidal Volume_min'\n",
      " 'Transferrin_max' 'Transferrin_min' 'Triglycerides_max'\n",
      " 'Triglycerides_min' 'Troponin T_max' 'Troponin T_min' 'Urea Nitrogen_max'\n",
      " 'Urea Nitrogen_min' 'Urea Nitrogen, Urine_max' 'Urea Nitrogen, Urine_min'\n",
      " 'Uric Acid_max' 'Uric Acid_min' 'Urobilinogen_max' 'Urobilinogen_min'\n",
      " 'Vancomycin_max' 'Vancomycin_min' 'Vitamin B12_max' 'Vitamin B12_min'\n",
      " 'WBC_max' 'WBC_min' 'White Blood Cells_max' 'White Blood Cells_min'\n",
      " 'pCO2_max' 'pCO2_min' 'pH_max' 'pH_min' 'pO2_max' 'pO2_min' 'tacroFK_max'\n",
      " 'tacroFK_min']\n"
     ]
    }
   ],
   "source": [
    "# reads all the csvs and writes them to parquet filesspark = SparkSession.builder \\\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"HostpitalMortalityClassifier\") \\\n",
    "    .config(\"spark.executor.memory\", MAX_MEMORY) \\\n",
    "    .config(\"spark.driver.memory\", MAX_MEMORY) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "LABEVENTS =  spark.read.parquet(data_dir + '/LABEVENTS.parquet')\n",
    "D_LABITEMS =  spark.read.parquet(data_dir + '/D_LABITEMS.parquet')\n",
    "ADMISSIONS =   spark.read.parquet(data_dir + '/ADMISSIONS.parquet')\n",
    "\n",
    "\n",
    "# sets the number of features to section by frequency\n",
    "n_features = 100\n",
    "\n",
    "# gets the top n_features most frequent features \n",
    "top_features = LABEVENTS\\\n",
    "                .join(D_LABITEMS, on = 'ITEMID', how='inner')\\\n",
    "                .dropna(subset=['VALUENUM'])\\\n",
    "                .groupby('LABEL')\\\n",
    "                .count().sort('count', ascending=False)\\\n",
    "                .limit(n_features).drop('count')\n",
    "\n",
    "\n",
    "## Data Transformations \n",
    "## gets the max and min value from the top n_features\n",
    "## groups by hospital admit id\n",
    "## creates a flag where the patient died \"Expired\" in the hosptial                                        \n",
    "data = LABEVENTS\\\n",
    ".join(D_LABITEMS, on = 'ITEMID', how='inner')\\\n",
    ".join(top_features, on='label', how='inner')\\\n",
    ".dropna(subset=['VALUENUM'])\\\n",
    ".groupby('HADM_ID')\\\n",
    ".pivot('LABEL')\\\n",
    ".agg(max('VALUENUM').alias('max'), min('VALUENUM').alias('min'))\\\n",
    ".join(ADMISSIONS.select('HADM_ID', col('HOSPITAL_EXPIRE_FLAG').alias('label')), on='HADM_ID', how='inner')\\\n",
    ".filter('label in (0,1)')\n",
    "\n",
    "## data Extraction to Pandas\n",
    "df = data.toPandas().set_index('HADM_ID')\n",
    "\n",
    "## create arrays for training model \n",
    "y = df.loc[:, 'label'].values\n",
    "X = df.drop('label', axis=1).values\n",
    "\n",
    "n_rows = X.shape[0]\n",
    "n_features = X.shape[1]\n",
    "feature_names_all = np.array(list(df.drop('label', axis=1).columns))\n",
    "label_prob = y.mean()\n",
    "print(F' n_rows: {n_rows}, n_features: {n_features}, label_prob {np.round(label_prob , 3)}')\n",
    "print(F'features: {feature_names_all}')\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Data Statics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% Hemoglobin A1c_max</th>\n",
       "      <th>% Hemoglobin A1c_min</th>\n",
       "      <th>Alanine Aminotransferase (ALT)_max</th>\n",
       "      <th>Alanine Aminotransferase (ALT)_min</th>\n",
       "      <th>Albumin_max</th>\n",
       "      <th>Albumin_min</th>\n",
       "      <th>Alkaline Phosphatase_max</th>\n",
       "      <th>Alkaline Phosphatase_min</th>\n",
       "      <th>Alveolar-arterial Gradient_max</th>\n",
       "      <th>Alveolar-arterial Gradient_min</th>\n",
       "      <th>...</th>\n",
       "      <th>White Blood Cells_min</th>\n",
       "      <th>pCO2_max</th>\n",
       "      <th>pCO2_min</th>\n",
       "      <th>pH_max</th>\n",
       "      <th>pH_min</th>\n",
       "      <th>pO2_max</th>\n",
       "      <th>pO2_min</th>\n",
       "      <th>tacroFK_max</th>\n",
       "      <th>tacroFK_min</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6614.000000</td>\n",
       "      <td>6614.000000</td>\n",
       "      <td>33661.000000</td>\n",
       "      <td>33661.000000</td>\n",
       "      <td>30996.000000</td>\n",
       "      <td>30996.000000</td>\n",
       "      <td>33573.000000</td>\n",
       "      <td>33573.000000</td>\n",
       "      <td>9884.000000</td>\n",
       "      <td>9884.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>56990.000000</td>\n",
       "      <td>37347.000000</td>\n",
       "      <td>37347.000000</td>\n",
       "      <td>47548.000000</td>\n",
       "      <td>47548.000000</td>\n",
       "      <td>37350.000000</td>\n",
       "      <td>37350.000000</td>\n",
       "      <td>921.000000</td>\n",
       "      <td>921.000000</td>\n",
       "      <td>58144.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.630215</td>\n",
       "      <td>6.614914</td>\n",
       "      <td>156.416149</td>\n",
       "      <td>42.653828</td>\n",
       "      <td>3.373439</td>\n",
       "      <td>3.013466</td>\n",
       "      <td>150.903524</td>\n",
       "      <td>101.232240</td>\n",
       "      <td>475.819102</td>\n",
       "      <td>412.899332</td>\n",
       "      <td>...</td>\n",
       "      <td>8.319279</td>\n",
       "      <td>51.336493</td>\n",
       "      <td>35.295204</td>\n",
       "      <td>7.264455</td>\n",
       "      <td>5.964260</td>\n",
       "      <td>256.436573</td>\n",
       "      <td>85.320214</td>\n",
       "      <td>14.397611</td>\n",
       "      <td>4.427904</td>\n",
       "      <td>0.100182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.778103</td>\n",
       "      <td>1.775684</td>\n",
       "      <td>704.995144</td>\n",
       "      <td>163.113849</td>\n",
       "      <td>0.662730</td>\n",
       "      <td>0.747922</td>\n",
       "      <td>187.566340</td>\n",
       "      <td>98.089175</td>\n",
       "      <td>135.059334</td>\n",
       "      <td>132.920845</td>\n",
       "      <td>...</td>\n",
       "      <td>6.470020</td>\n",
       "      <td>16.686125</td>\n",
       "      <td>9.421851</td>\n",
       "      <td>0.709379</td>\n",
       "      <td>1.015657</td>\n",
       "      <td>148.659425</td>\n",
       "      <td>63.776929</td>\n",
       "      <td>7.338076</td>\n",
       "      <td>2.601365</td>\n",
       "      <td>0.300246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-22.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.600000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.350000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>7.440000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.900000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>590.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>18.300000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>25460.000000</td>\n",
       "      <td>7035.000000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>4695.000000</td>\n",
       "      <td>3658.000000</td>\n",
       "      <td>794.000000</td>\n",
       "      <td>726.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>378.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1914.000000</td>\n",
       "      <td>630.000000</td>\n",
       "      <td>93.200000</td>\n",
       "      <td>25.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       % Hemoglobin A1c_max  % Hemoglobin A1c_min  \\\n",
       "count           6614.000000           6614.000000   \n",
       "mean               6.630215              6.614914   \n",
       "std                1.778103              1.775684   \n",
       "min                3.800000              3.800000   \n",
       "25%                5.600000              5.600000   \n",
       "50%                6.000000              6.000000   \n",
       "75%                6.900000              6.900000   \n",
       "max               22.000000             22.000000   \n",
       "\n",
       "       Alanine Aminotransferase (ALT)_max  Alanine Aminotransferase (ALT)_min  \\\n",
       "count                        33661.000000                        33661.000000   \n",
       "mean                           156.416149                           42.653828   \n",
       "std                            704.995144                          163.113849   \n",
       "min                              0.000000                            0.000000   \n",
       "25%                             18.000000                           13.000000   \n",
       "50%                             30.000000                           21.000000   \n",
       "75%                             66.000000                           35.000000   \n",
       "max                          25460.000000                         7035.000000   \n",
       "\n",
       "        Albumin_max   Albumin_min  Alkaline Phosphatase_max  \\\n",
       "count  30996.000000  30996.000000              33573.000000   \n",
       "mean       3.373439      3.013466                150.903524   \n",
       "std        0.662730      0.747922                187.566340   \n",
       "min        1.000000      0.900000                  3.000000   \n",
       "25%        2.900000      2.500000                 69.000000   \n",
       "50%        3.400000      3.000000                 96.000000   \n",
       "75%        3.800000      3.600000                156.000000   \n",
       "max        6.900000      5.700000               4695.000000   \n",
       "\n",
       "       Alkaline Phosphatase_min  Alveolar-arterial Gradient_max  \\\n",
       "count              33573.000000                     9884.000000   \n",
       "mean                 101.232240                      475.819102   \n",
       "std                   98.089175                      135.059334   \n",
       "min                    0.000000                        6.000000   \n",
       "25%                   57.000000                      380.000000   \n",
       "50%                   76.000000                      510.000000   \n",
       "75%                  108.000000                      590.000000   \n",
       "max                 3658.000000                      794.000000   \n",
       "\n",
       "       Alveolar-arterial Gradient_min  ...  White Blood Cells_min  \\\n",
       "count                     9884.000000  ...           56990.000000   \n",
       "mean                       412.899332  ...               8.319279   \n",
       "std                        132.920845  ...               6.470020   \n",
       "min                        -22.000000  ...               0.000000   \n",
       "25%                        310.000000  ...               5.400000   \n",
       "50%                        421.000000  ...               7.200000   \n",
       "75%                        524.000000  ...               9.700000   \n",
       "max                        726.000000  ...             378.000000   \n",
       "\n",
       "           pCO2_max      pCO2_min        pH_max        pH_min       pO2_max  \\\n",
       "count  37347.000000  37347.000000  47548.000000  47548.000000  37350.000000   \n",
       "mean      51.336493     35.295204      7.264455      5.964260    256.436573   \n",
       "std       16.686125      9.421851      0.709379      1.015657    148.659425   \n",
       "min        8.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "25%       42.000000     30.000000      7.350000      5.000000    124.000000   \n",
       "50%       48.000000     34.000000      7.440000      5.500000    230.000000   \n",
       "75%       56.000000     39.000000      7.500000      7.000000    390.000000   \n",
       "max      247.000000    165.000000     10.000000      9.000000   1914.000000   \n",
       "\n",
       "            pO2_min  tacroFK_max  tacroFK_min         label  \n",
       "count  37350.000000   921.000000   921.000000  58144.000000  \n",
       "mean      85.320214    14.397611     4.427904      0.100182  \n",
       "std       63.776929     7.338076     2.601365      0.300246  \n",
       "min        0.000000     1.200000     1.200000      0.000000  \n",
       "25%       46.000000     9.500000     2.700000      0.000000  \n",
       "50%       70.000000    14.100000     3.800000      0.000000  \n",
       "75%      100.000000    18.300000     5.500000      0.000000  \n",
       "max      630.000000    93.200000    25.700000      1.000000  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stats_path = 'data_stats.csv'\n",
    "data_stats = df.describe()\n",
    "data_stats.to_csv(data_stats_path)\n",
    "data_stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RFE in module sklearn.feature_selection._rfe:\n",
      "\n",
      "class RFE(sklearn.feature_selection._base.SelectorMixin, sklearn.base.MetaEstimatorMixin, sklearn.base.BaseEstimator)\n",
      " |  RFE(estimator, *, n_features_to_select=None, step=1, verbose=0, importance_getter='auto')\n",
      " |  \n",
      " |  Feature ranking with recursive feature elimination.\n",
      " |  \n",
      " |  Given an external estimator that assigns weights to features (e.g., the\n",
      " |  coefficients of a linear model), the goal of recursive feature elimination\n",
      " |  (RFE) is to select features by recursively considering smaller and smaller\n",
      " |  sets of features. First, the estimator is trained on the initial set of\n",
      " |  features and the importance of each feature is obtained either through\n",
      " |  any specific attribute or callable.\n",
      " |  Then, the least important features are pruned from current set of features.\n",
      " |  That procedure is recursively repeated on the pruned set until the desired\n",
      " |  number of features to select is eventually reached.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <rfe>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : ``Estimator`` instance\n",
      " |      A supervised learning estimator with a ``fit`` method that provides\n",
      " |      information about feature importance\n",
      " |      (e.g. `coef_`, `feature_importances_`).\n",
      " |  \n",
      " |  n_features_to_select : int or float, default=None\n",
      " |      The number of features to select. If `None`, half of the features are\n",
      " |      selected. If integer, the parameter is the absolute number of features\n",
      " |      to select. If float between 0 and 1, it is the fraction of features to\n",
      " |      select.\n",
      " |  \n",
      " |      .. versionchanged:: 0.24\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  step : int or float, default=1\n",
      " |      If greater than or equal to 1, then ``step`` corresponds to the\n",
      " |      (integer) number of features to remove at each iteration.\n",
      " |      If within (0.0, 1.0), then ``step`` corresponds to the percentage\n",
      " |      (rounded down) of features to remove at each iteration.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Controls verbosity of output.\n",
      " |  \n",
      " |  importance_getter : str or callable, default='auto'\n",
      " |      If 'auto', uses the feature importance either through a `coef_`\n",
      " |      or `feature_importances_` attributes of estimator.\n",
      " |  \n",
      " |      Also accepts a string that specifies an attribute name/path\n",
      " |      for extracting feature importance (implemented with `attrgetter`).\n",
      " |      For example, give `regressor_.coef_` in case of\n",
      " |      :class:`~sklearn.compose.TransformedTargetRegressor`  or\n",
      " |      `named_steps.clf.feature_importances_` in case of\n",
      " |      class:`~sklearn.pipeline.Pipeline` with its last step named `clf`.\n",
      " |  \n",
      " |      If `callable`, overrides the default feature importance getter.\n",
      " |      The callable is passed with the fitted estimator and it should\n",
      " |      return importance for each feature.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  estimator_ : ``Estimator`` instance\n",
      " |      The fitted estimator used to select features.\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of selected features.\n",
      " |  \n",
      " |  ranking_ : ndarray of shape (n_features,)\n",
      " |      The feature ranking, such that ``ranking_[i]`` corresponds to the\n",
      " |      ranking position of the i-th feature. Selected (i.e., estimated\n",
      " |      best) features are assigned rank 1.\n",
      " |  \n",
      " |  support_ : ndarray of shape (n_features,)\n",
      " |      The mask of selected features.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  The following example shows how to retrieve the 5 most informative\n",
      " |  features in the Friedman #1 dataset.\n",
      " |  \n",
      " |  >>> from sklearn.datasets import make_friedman1\n",
      " |  >>> from sklearn.feature_selection import RFE\n",
      " |  >>> from sklearn.svm import SVR\n",
      " |  >>> X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n",
      " |  >>> estimator = SVR(kernel=\"linear\")\n",
      " |  >>> selector = RFE(estimator, n_features_to_select=5, step=1)\n",
      " |  >>> selector = selector.fit(X, y)\n",
      " |  >>> selector.support_\n",
      " |  array([ True,  True,  True,  True,  True, False, False, False, False,\n",
      " |         False])\n",
      " |  >>> selector.ranking_\n",
      " |  array([1, 1, 1, 1, 1, 6, 4, 3, 2, 5])\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  Allows NaN/Inf in the input if the underlying estimator does as well.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  RFECV : Recursive feature elimination with built-in cross-validated\n",
      " |      selection of the best number of features.\n",
      " |  SelectFromModel : Feature selection based on thresholds of importance\n",
      " |      weights.\n",
      " |  SequentialFeatureSelector : Sequential cross-validation based feature\n",
      " |      selection. Does not rely on importance weights.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  .. [1] Guyon, I., Weston, J., Barnhill, S., & Vapnik, V., \"Gene selection\n",
      " |         for cancer classification using support vector machines\",\n",
      " |         Mach. Learn., 46(1-3), 389--422, 2002.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RFE\n",
      " |      sklearn.feature_selection._base.SelectorMixin\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, *, n_features_to_select=None, step=1, verbose=0, importance_getter='auto')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Compute the decision function of ``X``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like or sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : array, shape = [n_samples, n_classes] or [n_samples]\n",
      " |          The decision function of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |          Regression and binary classification produce an array of shape\n",
      " |          [n_samples].\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the RFE model and then the underlying estimator on the selected\n",
      " |         features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          The target values.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Reduce X to the selected features and then predict using the\n",
      " |         underlying estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array of shape [n_samples, n_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array of shape [n_samples]\n",
      " |          The predicted target values.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities for X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array of shape [n_samples, n_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape (n_samples, n_classes)\n",
      " |          The class log-probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like or sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array of shape (n_samples, n_classes)\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |  \n",
      " |  score(self, X, y)\n",
      " |      Reduce X to the selected features and then return the score of the\n",
      " |         underlying estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array of shape [n_samples, n_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      y : array of shape [n_samples]\n",
      " |          The target values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  classes_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.feature_selection._base.SelectorMixin:\n",
      " |  \n",
      " |  get_support(self, indices=False)\n",
      " |      Get a mask, or integer index, of the features selected\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : bool, default=False\n",
      " |          If True, the return value will be an array of integers, rather\n",
      " |          than a boolean mask.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      support : array\n",
      " |          An index that selects the retained features from a feature vector.\n",
      " |          If `indices` is False, this is a boolean array of shape\n",
      " |          [# input features], in which an element is True iff its\n",
      " |          corresponding feature is selected for retention. If `indices` is\n",
      " |          True, this is an integer array of shape [# output features] whose\n",
      " |          values are indices into the input feature vector.\n",
      " |  \n",
      " |  inverse_transform(self, X)\n",
      " |      Reverse the transformation operation\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array of shape [n_samples, n_selected_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_r : array of shape [n_samples, n_original_features]\n",
      " |          `X` with columns of zeros inserted where features would have\n",
      " |          been removed by :meth:`transform`.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Reduce X to the selected features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array of shape [n_samples, n_features]\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_r : array of shape [n_samples, n_selected_features]\n",
      " |          The input samples with only the selected features.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      " |      and returns a transformed version of `X`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input samples.\n",
      " |      \n",
      " |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      " |          Target values (None for unsupervised transformations).\n",
      " |      \n",
      " |      **fit_params : dict\n",
      " |          Additional fit parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "help(RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Splitting\n",
    "Data splitting via Statified Shuffle Split\n",
    "\n",
    "#### Feature Selection pyImpetous "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Feature Names ['Anion Gap_min', 'Asparate Aminotransferase (AST)_min', 'Base Excess_min', 'Bicarbonate_max', 'Chloride_min', 'Glucose_min', 'Hematocrit_max', 'Lactate_max', 'Lactate_min', 'Neutrophils_max', 'Oxygen_max', 'PT_min', 'PTT_max', 'PTT_min', 'Platelet Count_max', 'Platelet Count_min', 'RDW_min', 'Sodium_max', 'Urea Nitrogen_max', 'Urea Nitrogen_min', 'White Blood Cells_max', 'White Blood Cells_min', 'pCO2_max', 'pCO2_min', 'pO2_max']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "splitter = StratifiedKFold(shuffle=True)\n",
    "train_index, test_index = next(splitter.split(X, y))\n",
    "\n",
    "selector = RFE(DecisionTreeClassifier(), step=5, n_features_to_select=25)\n",
    "\n",
    "#featuer selection via recussive feature elemination \n",
    "selector= selector.fit(pd.DataFrame(X[train_index, :], columns=feature_names_all).fillna(0), \n",
    "                               y[train_index])\n",
    "\n",
    "support_index = selector.get_support()\n",
    "feature_names = feature_names_all[support_index]\n",
    "\n",
    "X_train = df.iloc[train_index, :].loc[:, feature_names] \n",
    "X_test = df.iloc[test_index, :].loc[:, feature_names] \n",
    "y_train = y[train_index]\n",
    "y_test = y[test_index]\n",
    "\n",
    "feature_names = list(X_train.columns)\n",
    "print(F'Selected Feature Names {feature_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeliing Fitting Using AutoML\n",
    "Searchs through models to find best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default limit of max_batches=1.\n",
      "\n",
      "Generating pipelines to search over...\n",
      "8 pipelines ready for search.\n",
      "\n",
      "*****************************\n",
      "* Beginning pipeline search *\n",
      "*****************************\n",
      "\n",
      "Optimizing for Log Loss Binary. \n",
      "Lower score is better.\n",
      "\n",
      "Using SequentialEngine to train and score pipelines.\n",
      "Searching up to 1 batches for a total of 9 pipelines. \n",
      "Allowed model families: decision_tree, extra_trees, random_forest, linear_model, xgboost, catboost, lightgbm\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807d6ed0739a4790b208fd12fbb8f011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines+markers',\n",
       "              'name': 'Best Score',\n",
       "              'type'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Baseline Pipeline: Mode Baseline Binary Classification Pipeline\n",
      "Mode Baseline Binary Classification Pipeline:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 3.460\n",
      "\n",
      "*****************************\n",
      "* Evaluating Batch Number 1 *\n",
      "*****************************\n",
      "\n",
      "Elastic Net Classifier w/ Imputer + Undersampler + Standard Scaler:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.251\n",
      "Decision Tree Classifier w/ Imputer + Undersampler:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.314\n",
      "Random Forest Classifier w/ Imputer + Undersampler:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.235\n",
      "LightGBM Classifier w/ Imputer + Undersampler:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.192\n",
      "Logistic Regression Classifier w/ Imputer + Undersampler + Standard Scaler:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.244\n",
      "XGBoost Classifier w/ Imputer + Undersampler:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.192\n",
      "Extra Trees Classifier w/ Imputer + Undersampler:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.285\n",
      "CatBoost Classifier w/ Imputer + Undersampler:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.486\n",
      "\n",
      "Search finished after 00:25            \n",
      "Best pipeline: LightGBM Classifier w/ Imputer + Undersampler\n",
      "Best pipeline Log Loss Binary: 0.191506\n"
     ]
    }
   ],
   "source": [
    "\n",
    "automl = AutoMLSearch(X_train=X_train, y_train=y_train, problem_type='binary')\n",
    "with  warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    automl.search()\n",
    "model = automl.best_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Performance\n",
    "Calcuates Model Peformace on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score: 0.9280783655549867 on test\n",
      "roc_auc_score: 0.9661526381442574 on train\n",
      "\n",
      "*************************************************\n",
      "* LightGBM Classifier w/ Imputer + Undersampler *\n",
      "*************************************************\n",
      "\n",
      "Problem Type: binary\n",
      "Model Family: LightGBM\n",
      "Number of features: 25\n",
      "\n",
      "Pipeline Steps\n",
      "==============\n",
      "1. Imputer\n",
      "\t * categorical_impute_strategy : most_frequent\n",
      "\t * numeric_impute_strategy : mean\n",
      "\t * categorical_fill_value : None\n",
      "\t * numeric_fill_value : None\n",
      "2. Undersampler\n",
      "\t * sampling_ratio : 0.25\n",
      "\t * min_samples : 100\n",
      "\t * min_percentage : 0.1\n",
      "\t * sampling_ratio_dict : None\n",
      "3. LightGBM Classifier\n",
      "\t * boosting_type : gbdt\n",
      "\t * learning_rate : 0.1\n",
      "\t * n_estimators : 100\n",
      "\t * max_depth : 0\n",
      "\t * num_leaves : 31\n",
      "\t * min_child_samples : 20\n",
      "\t * n_jobs : -1\n",
      "\t * bagging_freq : 0\n",
      "\t * bagging_fraction : 0.9\n"
     ]
    }
   ],
   "source": [
    "# predicts the test data\n",
    "test_preds = model.predict_proba(X_test).iloc[:, 1]\n",
    "test_pred_labels = model.predict(X_test)\n",
    "\n",
    "# calcuates metrics on test data\n",
    "test_f1 = f1_score(y_test, test_pred_labels)\n",
    "test_acc_balanced = balanced_accuracy_score(y_test, test_pred_labels)\n",
    "test_acc = accuracy_score(y_test, test_pred_labels)\n",
    "test_precision = precision_score(y_test, test_pred_labels)\n",
    "test_recall = recall_score(y_test, test_pred_labels)\n",
    "test_auc_score = roc_auc_score(y[test_index], test_preds)\n",
    "print(F'roc_auc_score: {test_auc_score } on test')\n",
    "\n",
    "## predicts the training data \n",
    "train_preds = model.predict_proba(X_train).iloc[:, 1]\n",
    "train_pred_labels = model.predict(X_train)\n",
    "\n",
    "# calculates metrics on training data \n",
    "train_f1 = f1_score(y_train, train_pred_labels)\n",
    "train_acc_balanced = balanced_accuracy_score(y_train, train_pred_labels)\n",
    "train_acc = accuracy_score(y_train, train_pred_labels)\n",
    "train_precision = precision_score(y_train, train_pred_labels)\n",
    "train_recall = recall_score(y_train, train_pred_labels)\n",
    "train_auc_score = roc_auc_score(y_train, train_preds)\n",
    "print(F'roc_auc_score: {train_auc_score} on train')\n",
    "\n",
    "# gets params Artifacts for logging mlflow model\n",
    "n_cases = np.sum(y == 1)\n",
    "n_controls = np.sum(y == 0)\n",
    "n_train_obs = X_train.shape[0]\n",
    "n_test_obs = X_test.shape[0]\n",
    "n_features = X_train.shape[1]\n",
    "train_label_prob = y_train.mean()\n",
    "test_label_prob = y_test.mean()\n",
    "desc = str(model.describe())\n",
    "model_type = type(model)\n",
    "split_type = type(splitter)\n",
    "input_example = X_train.head().fillna(0)\n",
    "signature = infer_signature(X_train.head().fillna(0), model.predict_proba(X_train.head().fillna(0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance\n",
    "save feature importance to a dictionary for later logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pCO2_max</th>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sodium_max</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platelet Count_max</th>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose_min</th>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White Blood Cells_min</th>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       importance\n",
       "feature                          \n",
       "pCO2_max                      213\n",
       "Sodium_max                    179\n",
       "Platelet Count_max            174\n",
       "Glucose_min                   170\n",
       "White Blood Cells_min         160"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = model.feature_importance.set_index('feature')\n",
    "\n",
    "# dumps feature importance to a dictionary for logging as an artifact\n",
    "imp_dict = imp.to_dict()['importance']\n",
    "imp_json_path = 'feature_importance.json'\n",
    "with open(imp_json_path, 'w') as f:\n",
    "    json.dump(imp_dict,f)\n",
    "\n",
    "imp.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Tracking\n",
    "Uses an mlflow tracking server to save the model, parameters and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking uri: http://localhost:5000\n",
      "Artifact uri: /home/matthew/data/physio/mlruns/1/eea19754655d47688043ab19aee8c9bd/artifacts\n",
      "logging experiment_id: \"1\" run_id :\"eea19754655d47688043ab19aee8c9bd\" completed\n"
     ]
    }
   ],
   "source": [
    "artifact_path = 'Model'\n",
    "data_grain = 'HADM_ID'\n",
    "label_name = 'HOSPITAL_EXPIRE_FLAG'\n",
    "data_source = 'PhysioMimicIII'\n",
    "run_name = 'evalML_rfe'\n",
    "experiment_id = 1\n",
    "tracking_uri = \"http://localhost:5000\"\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "experiment_id=1\n",
    "with mlflow.start_run(run_name=run_name, experiment_id=experiment_id) as run:\n",
    "    \n",
    "    tracking_uri = mlflow.get_tracking_uri()\n",
    "    artifact_uri = mlflow.get_artifact_uri()\n",
    "    print(\"Tracking uri: {}\".format(tracking_uri))\n",
    "    print(\"Artifact uri: {}\".format(artifact_uri))\n",
    "    mlflow.sklearn.log_model(model,\n",
    "                         artifact_path=artifact_path, \n",
    "                         signature=signature,\n",
    "                         input_example=input_example\n",
    "                        )\n",
    "    mlflow.log_artifact(imp_json_path)\n",
    "    mlflow.log_artifact(data_stats_path)\n",
    "    mlflow.log_param('data_source', data_source)\n",
    "    mlflow.log_param('label_name', label_name)\n",
    "    mlflow.log_param('data_grain', data_grain)\n",
    "    mlflow.log_param('n_cases', n_cases)\n",
    "    mlflow.log_param('n_controls', n_controls)\n",
    "    mlflow.log_param('n_train_obs', n_train_obs)\n",
    "    mlflow.log_param('n_test_obs', n_test_obs)\n",
    "    mlflow.log_param('n_features', n_features)\n",
    "    mlflow.log_param('train_label_prob', train_label_prob)\n",
    "    mlflow.log_param('test_label_prob', test_label_prob)\n",
    "    mlflow.log_param('desc', desc)\n",
    "    mlflow.log_param('model_type',model_type)\n",
    "    mlflow.log_param('split_type',split_type)\n",
    "    mlflow.log_param('feature_selection', type(selector))\n",
    "    mlflow.log_metric('train_f1', train_f1)\n",
    "    mlflow.log_metric('train_acc_balanced', train_acc_balanced)\n",
    "    mlflow.log_metric('train_acc', train_acc)\n",
    "    mlflow.log_metric('train_precision', train_precision)\n",
    "    mlflow.log_metric('train_recall', train_recall)\n",
    "    mlflow.log_metric('train_auc_score', train_auc_score)\n",
    "    mlflow.log_metric('test_f1', test_f1)\n",
    "    mlflow.log_metric('test_acc_balanced', test_acc_balanced)\n",
    "    mlflow.log_metric('test_acc', test_acc)\n",
    "    mlflow.log_metric('test_precision', test_precision)\n",
    "    mlflow.log_metric('test_recall', test_recall)\n",
    "    mlflow.log_metric('test_auc_score', test_auc_score)\n",
    "    run_id = run.info.run_id\n",
    "    experiment_id = run.info.experiment_id \n",
    "    mlflow.end_run()\n",
    "    print(F'logging experiment_id: \"{experiment_id}\" run_id :\"{run_id}\" completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
